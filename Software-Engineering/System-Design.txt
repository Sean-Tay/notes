System Design:
	Abbreviations:
		CDN:					Content Delivery Network.
	
	Description: Problems designed to test your ability to keep progressing through scenarios with Limited Detail but Greater Flexibility.
	
	Resources:
		
	
	Concepts:
		Reliability: 			Working in the face of Faults for both Software and Hardware.
			Continuous Availability: Full Availability 24/7.
			High Availability:	Operational Performance for a higher than normal period.

		Scalability: 			Working as the System faces increased Traffic, Usage, and Data.
			Horizontal Scaling: Adding more Resources to meet demand (i.e. Quantity).
			Vertical Scaling:	Upgrading existing Resources to be more capable (i.e. Quality).

		Maintenability: 		Ease at which parts of the System can be modified / added / removed by others.

		Response Time:			The time it takes for a Client to receive a Response from a submitted Request.
		Latency:				The time in which a Pending Request is waiting to be handled by the System.
			Tail Latency:		A metric which describes the percentage of Requests which would not exceed a specified Latency Amount.

		Bandwidth:				The maximum number of Requests that the System can theoretically handle at a given time.
		Throughput:				The number of Requests that the System can actually handle at a given time.

		80-20 Rule: 			20% of Writes will lead to 80% of subsequent Reads.

		Forward Proxy:			An intermediary that sits between a User and the Internet, acting on behalf of the User.
		Reverse Proxy: 			An intermediary that sits between a Web Application and the Internet, acting on behalf of the Web Application.

		Service Oriented Architecture: Style of Software Design where Servcies are provided to other Components by Application-related Components, through a Communication Protocol over a Network.

		API Gateway:			An Interceptor for API / Microservice Requests that acts as a Single Entry Point to help implement Standardized Access across all APIs / Microservices.
	
	Details:
		Typical System Components grouped via Function:
			Data Storage:
				Databases

				Distributed File Storage: Store Files in a System with Redundancy / Replication for Availability.
					Examples:
						Hadoop: Tailored towards eventual Data Processing of the Data in the Files stored.

			System Data Transport:
				Message Queue: Enables Asynchronous Communication between two or more Components.
					Behaviour:
						Messages produced by Producer Nodes, consumed by at least one Consumer Node.

						A Messaging Broker is a Database specialized for Streaming, typically managing the various Queues.
							Messages can either be consumed and deleted, or consumed and kept.
							Messages can either be sent to all Subscribers, or sent to Subscribers in a Round-Robin fashion (i.e. Load Balancing).

						Even if the Messages are kept in the Queue, Messages may still be processed out-of-order:
							Consumers consume Messages at different speeds.
							Varying Network Speeds to different Consumers.
							Messages are not all equal.

						Queues should keep track of the Message Index, and only consider a Message consumed when Consumers send an acknowledgement.

						Fault Tolerance: Involves ensuring Messages are processed only exactly once.
							At least once: Occasionally checkpoint Stream State to Disk to restart from most recent checkpoint on crash.
							At most once: Idempotent Operations via UUID; Atomic Transactions via Two-Phase Commit.

					Types:
						In-Memory: Higher Throughput - better for larger Messages as Memory is faster than Disk; Messages are deleted once Consumer acknowledges the Message.
						Log-Based (Disk): Persistent Append-Only Log; can be Partitioned and Replicated to improve number of Consumers and Fault Tolerance.
							One Consumer per Partition to maintain Message Order per Partition.

					Examples:
						Kafka
						RabbitMQ
						Azure Bus Service
						AWS SQS
						Google Cloud Pub/Sub

			Optimization:
				(In-Memory) Cache: Simple Key-Value Object Store that is very quick on Read / Write operations. Can be used for storing information about User Sessions.
					Examples:
						Memcached
						Redis

			Data Processing:
				Custom Services: The Components in the System that executes Application-specific Logic.
					Examples:
						Kafka Consumer

						REST Server
						Serverless Function

				Batch: Offline; Bounded Data - assumes all Data available before starting.
					Examples:
						Hadoop MapReduce
						Spark Job

					Scenarios:
						Sorting

				Streaming: Online; Unbounded Data - not all Data available at once. Usually leverages Messaging Queues to manage Data Flow.
					Scenarios:
						Logging Metrics: Usually involves aggregation of Events into fixed Time Intervals.
							Challenges: 
								Which time do we use to determine when the Event is active?
								If an Event was created within a Time Interval and is processed by the System outside of the Time Interval, do we retrospectively add it into the gathered data for the Time Interval?

							Time Interval Types:
								Tumbling Windows: Distinct Intervals of Fixed Length.
								Hopping Windows: Overlapping Intervals of Fixed Length.
								Sliding Windows: "Moving" Interval of Fixed Length; old Events are removed from the Interval when it "moves".

						Change Data Capture - Streaming a Database's Write-Ahead Log to update other Components that maintain derived Data (i.e. Caches) to keep them up-to-date whenever a Database Write happens.
						Event Sourcing - Purpose same as Change Data Capture, but Database-agnostic; stream User-defined Events rather than Database Writes.

						Maintaining top N Items according to some metric.

					Handling Joins: For when Messages have associations to one another; usually involves keeping some local Stream-specific State.
						Stream-Stream Joins: Joining two different Events within a Stream (i.e. Search Event + Search Result Click Event); uses an Index to temporarily store / track Events of one type, so that when the other type of Event comes in, the Index can be used to retrieve the first Event for joining.
						Stream-Table Joins: Enriching Events with Data in a Table of a Database; uses a local copy of the Table which is kept up to date by Change Data Capture. 
						Table-Table Joins: Enriching Events with Data in more than one Table of a Database; uses a local copy of the results from the Database Query required via Change Data Capture.

			User-Facing Data Transport:
				Load Balancer: A Reverse Proxy that distributes Network Traffic across different Cluster Nodes in a Distributed System.
					Examples:
						Cloudflare
						DigitalOcean
						Azure Load Balancer
						WS Load Balancer
						Google Cloud

						HAProxy

				DNS: Translates a Human-Readable Domain Name into an IP Address.
					Examples:
						Cloudflare
						Route 53

				CDN: A Cache for all kinds of Static Content.
					Types:
						Push CDN: Application is responsible for pushing updated content to the CDN and maintaining the URL used to access them. Works well when content is not updated frequently.
						Pull CDN: CDN pulls content from Application when the first User initiates a Request for that content. A TTL can be ascribed to such content in order to save space on the CDN. Works well with Applications that have heavy traffic, as no additional traffic incurred from pushing content to CDN unnecessarily.

					Examples:
						Fastly
						Cloudflare CDN
						Azure CDN
						AWS CloudFront
						Google CDN

				Web Server (Reverse Proxy): A running Process on a Host Machine that is designed to just serve Static Content and Resources via HTTP. Requests for Dynamic Content gets sent to the App Server, although Plugins can be installed to generate Dynamic Content via Scripting Languages as well.
					Examples:
						NGINX

			Data Presentation:
				Desktop
				Web
				Mobile

		Systems are Designed with the intent of being Reliable, Scalable and Maintenable.
			Reliable:
				Strategies:
					Failover:
						Active-Passive: Only one Node is actively handling Requests - the rest of the cloned Nodes are reserved for backup (either in Cold or Hot State). The Active Node is sending a regular heartbeat to the Passive Nodes - after a certain duration of not receiving a heartbeat one of the Passive Nodes takes over the Active Node's IP Address and role.

						Active-Active: More than one Node is actively handling Requests. The DNS and Application Logic needs to know about all Active Nodes.

					Replication: See Database Notes.

				(Availability) Uptime Standards:
					90% -> 36.5 Days Offline per Year
					95% -> 18.25 Days Offline per Year
					99% -> 3.65 Days Offline Per Year
					99.9% -> 8.77 Hours Offline Per Year
					99.99% -> 1 Hour Offline Per Year
	
		Synchronization in Distributed Systems:
			Time:
				Network Time Protocol: Mechanism occasionally used by Machines to synchronize their internal clocks.
				Monotonic Clock: Only used to measure Time Deltas - specific value of the Clock means nothing.
			
			Consensus:
				Fencing Token: Token with a monotonically increasing value used in Consensus-based Distributed Scenarios to ensure correct behaviour even when parts of it have been paused / are unreliable. Entities obtain a Token from a Token Service, and will only be successful in performing the operation on another Entity if the other Entity has not seen a Token with a higher value before.

		Load Balancing in Distributed Systems: 
			Constriants:
				Minimal Disruption: Must ensure that the majority of Items which already have a Node in the System to go to are not unnecessarily reshuffled when Nodes are added to / removed from the System, reducing potential Network Congestion.

			Techniques:
				Consistent Hashing: A Technique used to facilitate Load Distribution within a Distributed System (Cluster).
					Approach:
						Given the Range of a Hash Function (Output Range), distribute Node IDs uniformly along the Range (to avoid Hotspots).
							The position / hash of each Node ID must be tracked to the Node ID itself for faster lookup (i.e. Hashmap of Node ID hashes to Node IDs).
								Variations of the Node IDs can be used for multiple insertions.

							The Output Range does not need to be completely filled, leave space for more Nodes to be added later.

						For a given Item, subject the Item's Key to the Hash Function to get the corresponding Hash Value.
						Given the Hash Value, go in one direction (must be same throughout runs) along the Output Range until a Node ID is reached. The Node that corresponds to that Node ID will be the one to handle the Item.

				Rendezvous Hashing / Highest Random Weight Hashing: A simpler and more general version of Consistent Hashing. Allows for multiple Clients to send an Item to a specific Node in the System each time.
					Approach:
						All Clients need to agree on the same Hash Function. The Hash Function maps a pair containing an Item's Key and a Node ID to a given score.
							Nodes with higher capabilities can have their Node IDs be assigned slots multiple times in the Hash Function, or use the Skeleton variant for non-integer multiples.

						For a given Item, subject the Item's Key to multiple calls of the Hash Function, each call corresponding to a possible Node to send the Item to. The Node whose call has the highest score is the one that will take the Item.
							If the Node is deemed to have failed, pick the next highest.

	Commands:
		
	
