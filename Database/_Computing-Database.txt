Database
	Abbreviations: 
		DBMS:					DataBase Management System.

		CMDB: 					Configuration Management Database.

	Description: 
		A Database is an Organized, Long-Term Collection of Data, generally Stored, Managed and Accessed via some System.
	
	Resources:
	
	Concepts:
		Data Types:
			Structured Data:	Data whose Elements are Directly Addressible (i.e. Tabular or Array-like Data).
			Semi-Structured Data: Data whose Elements may not be Directly Addressible, but still contain other forms of Organizational Properties (i.e. Tagged Data: XML).
			Unstructured Data:	Data which is currently observed to have no immediately helpful Pre-Defined Format (i.e. Binary Data: PDFs).

		Attribute / Key / Field: Refers to a characteristic of some type of Entity.
		Record:					A collection of Attributes pertaining to some instance of an Entity.
		Collection:				A group of Records.

		Forward Index:			A Data Structure that maps the Record to the Record's Content.
		Inverted Index: 		An additional Data Structure (separate from the Collection) that allows for quick access of a Full Record on Disk via a defined subset of the Record's Data.
			Sparse Index:		Contains a mapping only for every n Records in the Collection to the Disk Location. Typically used in Multi-Level Indexing (i.e further Indexing of a Dense or overly Large Index).
			Dense Index:		Contains a mapping for every Record in the Collection to the Disk Location.

		Database Partitioning:
			Horizontal Partitioning: Different Records into Separate Collections (e.g. Sharding).
			Vertical Partitioning: Different Record Attributes into Separate Collections (e.g. Normalization or simple Record Splitting).

		Replication:			Having Redundant Copies of the Data in a Database stored in multiple Machines so that if one fails, dependent Applications can still use the other Machines for Data Retrieval. Also helps to reduce operational load per Instance.
		Replica:				A Machine within a Replicated Database.

		Data Consistency: 		Degree of Consistency between Copies of Data within one or more Database Clusters (in different Data Centers). Usually seen as a tradeoff with Database Performance.
		Consistency Model: 		Defines a contract in which Reads and Writes to Data will guarantee certain predictable behaviour in the Data. One or more can be implemented to achieve greater Consistency in exchange for decreasing Performance.

	Details:
		Database Objectives:
			Persistent Data Storage: Data should not be lost when the Database shuts down.

			Fast Writes
			Fast Reads
				Data should be stored contiguously on Disk to minimize the amount of Disk Lookups required (known to be expensive as it involves mechanical movement of the Storage Disks at the Hardware level).

				Optimization Techniques:
					Append-Only: New Records / Updated-versions of Past Records are simply appended to the end of the Collection without concern for Duplication. Lookups can be optimized by traversing from the end of the Collection.

					Indexes: 	Improves speed of Lookups, but imposes additional operations during Insertions / Deletions, and adds to the Disk Space required by the Collection.
						Background:
							The benefit of the Index is that it is able to reduce the number of Disk Block accesses maximally required to find the actual Disk Block that stores the complete Record, because only the necessary subset of the Record's Data is stored in each Disk Block used by the Index (thus each Disk Block can store more Block Addresses).
								The optimization is more effective when Records are large => Less Records per Disk Block => More Disk Block Lookups without an Index.

							The Data within the Index is usually stored in sorted order, but the actual Records in the Collection on Disk may not be stored in sorted order.

						Types:
							Hashmaps: Index Keys map to Memory Addresses (Byte Offsets) in Disk.
								Pros:
									Compatable with the Append-Only method of adding new Records to the Collection.
									Allows access to Records in Constant Time.

								Cons: 
									Entire Hashmap has to be In-Memory for it to be effective - useful for only small Datasets.
									Not good for Range Queries, as Data within the Index is unsorted.

							LSM Trees + Immutable SS Tables: 
								Approach:
									Full Records realized from Database Writes are first placed in an In-Memory Balanced Binary Search Tree, with the Key used in the BST being the Index Key(s).
										To increase persistence, keep a Log on Database Writes that can be used to restore the In-Memory BBST after a Database Outage.

									When Tree gets too large, a Sorted SS Table is generated via BST In-Order Traversal and is transferred to Disk.
										The Tree gets emptied each time a SS Table is generated.

									There can be duplicate Keys between multiple Tables (and the Tree itself) - simply prioritise looking for the Key in the Tree, followed by the youngest SS Table to the oldest.
										Sparse Hashmaps with Memory Addresses + Binary Search on Table Keys can be additionally used to optimize lookups within an SS Table.
										Bloom Filters can be additionally used to optimize lookups between SS Tables.

										Tables can be combined in the same approach that Merge Sort uses to combine 2 Sorted Lists - Linear Time Background Operation.
											Prioritise the Key-Value Pair that is in the younger SS Table over the older SS Table.

								Pros:
									Higher Write Throughput due to Records being placed In-Memory at first.
									Uses the Append-Only method of adding new Records to the Collection.
									Good for Range Queries (that only use the Keys in the Index), as the Data in the Index is internally Sorted.

								Cons:
									Relatively Slow Reads for Keys that do not exist in the Collection.
									Merging Process for SS Tables can take up Background Resources.

							B Trees / B+ Trees: An extension of a Binary Search Tree - m-way Search Tree, but with constraints on how new Elements are inserted to prevent degenerate Trees.
								Approach:
									Each Node in the Tree is stored in one Disk Block.

									In the Non-Leaf Nodes, Keys of the Records used in the Index are stored alongside the pointers to next Node / Disk Block.
										For very large Collections, a Multi-Level Index may be used to avoid sequential Disk Block lookups in the original Index.
											At Higher Levels, the Keys stored in a Node / Disk Block becomes more sparse:
												Level 1: Keys 1 2 3, 4 5 6, 7 8 9, 10 11 12, 13 14 15, ...
												Level 2: Keys 1 4 7, 10 13 16, ...
												Level 3: Keys 1 10 19, ...

									Complete Records are only stored at the Leaf Nodes.

								Behaviour:
									Time Complexities:
										- Search / Update: O(logn)
										- Insertion: O(logn)
										- Deletion: O(logn)
									
									B-Tree Properties: 
										- Each Node can now store up to m-1 Elements, and m references to Children Nodes (m Degree / Order).
											- References to Child Nodes can be visualized as being stored 'between' the Elements.
											- Element Order in each Node is important.
										
										- Self-Balancing Properties:
											- All Non-Root Nodes with Children should have at least ceil(m/2) Child Nodes.
												- A Child Node can only be created if this property is fulfilled for the given Non-Leaf Node.

											- All Leaf Nodes should have at least ceil(m/2) - 1 Elements.

											- All Leaf Nodes (Nodes with no Children) should be at the same Level.
												- (Proactive) Insertion: Advantageous of not visiting a Node twice.
													- Bottom-Up: Tree grows upwards ; actual Element Insertion should only occur at a Leaf Node.
													- Traverse down from the Root Node to a Leaf Node.
														- If a given Node during Traversal is full, split the Node into 2 Child Nodes, and take the median Element from the original Node and set it to a Parent Node.
															- Left Bias: Resultant Left Child will have more Elements.
															- Right Bias: Resultant Right Child will have more Elements.

														- Continue Traversal from one of the Child Nodes.
												
												- (Proactive) Deletion: 
													- Traverse down from the Root Node.
														- If Element is in Non-Leaf Node:
															- If the Child Node that precedes / succeeds the Element has at least ceil(m/2)-1 Elements:
																- Obtain the Predecessor / Successor of the Element, depending on which Child Node has enough Elements.
																- Replace Element with Predecessor / Successor Element.
																- Delete Predecessor / Successor - guaranteed to be in Leaf Node.
																
															- Else: Both Child Nodes has less than ceil(m/2)-1 Elements:
																- Merge Both Child Nodes together, set Element to be Median Key of Child Node.
																- Traverse to new Child Node, and recursively delete Key from Child Node.

																- Note: Parent may have less than ceil(m/2)-1 Elements as a result of this operation, but this will be resolved in subsequent Deletes.

														- Else: Element is not in Current Non-Leaf Node.
															- Determine next Child Node to traverse to.

															- If Child Node has less than the minimum ceil(m/2)-1 Elements:
																- If an immediate Sibling Node has at least ceil(m/2) Elements, execute a left or right Rotation on one of the neighbouring Parent Elements.
																	- Send the neighbouring Parent Element down to the Child Node.
																	- Set the Predecessor or Successor Element of the Sibling Node in the Parent Element's position.
																- If both immediate Sibling Nodes have less than ceil(m/2) Elements, merge one of the Siblings together with the Child Node, with one the Parent Element becoming the Median Element of the Child Node.

															- Continue Traversal.
															- If Traversal has reached a Leaf Node, delete Element from Leaf Node if it exists.

									B+ Trees Properties:
										- Does not need to traverse the whole Tree for Sequential Access:
											- All Non-Leaf Nodes have their Elements in the Leaf Nodes as well.
											- All Leaf Nodes will be connected together like a Linked List from left to right.

								Pros:
									Higher Read Throughput - Sub-Linear Time Tree Traversal.
									Good for Range Queries (that only use the Keys in the Index), as the Data in the Index is internally Sorted.

								Cons:
									Relatively Slow Writes, as multiple Disk Blocks are accessed after each Write to update the Index.
	
			High Availability:
				Replication:
					Consistency Models: In descending order of Operational Performance:
						Eventual Consistency: Each Read on an Object is only guaranteed to return the result of applying a subset of Writes to that Object thus far (e.g. Writes 2 to 3, Writes 1 to 4, Writes 1 & 3 to 5) in the short term. This means that each Read has a chance to return a version of the Object that has never actually existed.

						Consistent Prefix: Each Read on an Object is guaranteed to return the result of applying an ordered sequence of Writes on an Object thus far, starting from the first Write (e.g. Writes 1 to 3, Writes 1 to 2, Writes 1 to 5). This means that each Read will return a version of the Object that has actually existed at some point in time.

						Session Consistency: Data Abnormalities should not occur for Reads and Writes during a limited period of time.
							Monotonic Reads: Each Read in a sequence of Reads on an Object is guaranteed to return the result of applying at least the same subset of Writes on the Object thus far as the previous Read (e.g. Writes 3 to 4, Writes 3 to 4, Writes 1 & 3 to 4, Writes 1 to 5).
							Read My Write: The result of all Writes to an Object done by a Client is guaranteed to be observable in the Client's subsequent Reads done on the same Object. Strong Consistency for the Client, Eventual Consistency for others.

						Bounded Staleness: Each Read on an Object is guaranteed to give the result of applying at least x Writes to that Object thus far (e.g. at least Writes 1 to 3, if x = 3 => Writes 1 to 3 & 5).

						Strong Consistency: A Read is guaranteed to return the result of applying all Writes on an Object thus far. Performance-intensive; depending on use case, it may be possible to use the weaker Consistency Models for the same effect. Note that this is technically Bounded Staleness with x = n.

					Types:
						Synchronous: Writes not considered successful until all Instances in the Cluster completes the Write Transaction. Strong Consistency, but slower Speed.

						Asynchronous: Writes considered successful when the Instance that was assigned the Write Transaction completes it. Faster Speed, but Clients may get stale / inconsistent Reads due to Eventual Consistency.
							Server / Database should simply return the written Data back to the Client that triggered the Write upon Success, or Read only from Leaders for editable Data (Read My Write Consistency).
							Each Client should only refer to one Instance for updates throughout the operation (Consistent-Prefix + Monotonic Reads Consistency), as different Replicas synchronize with a particular Write at different Speeds (Back-in-Time syndrome).
							Writes with Casual Relationships should ideally happen on the same Disk Partition (Consistent Prefix Reads), otherwise they might not make sense when they are Read (different Read Speeds for different Disk Partitions).

					Strategies:
						Single-Leader: All Writes to one Leader. Reads can come from any Replica (Follower) in the Cluster.
							Characteristics:
								Leader sends list of updates to other Followers via a Replication Log.
									Implementation:
										SQL Statements (for Relational Databases): Not ideal as SQL Statements can be non-deterministic (e.g. reference Current Time, which can be different per Replica).
										Internal Append-only Log: Describes which Bytes were changed. Not ideal as different Instances might have the affected Data in different Locations.
										Logical Log: Describes which Data was modified and how. Better future-proofing if underlying Database Engine changes.

								Adding a Follower: Initialize the Follower with a consistent snapshot of the Data in the Leader (associated with some position in the Replication Log), and then update to the latest State via the Replication Log.

								Pros:
									Single Source of Truth => no Conflicts to resolve.
								
								Cons:
									All Writes going to a single Instance, so Write Throughput is lower.
										Can consider Sharding, and having different Leaders for each subset of the Data.

							Scenarios:
								Follower Failure: On reboot, fetch all changes from the Leader, and implementing the changes starting from its last position in the Replication Log.

								Leader Failure / Failover: Determine a new Leader based on some Consensus / most up-to-date Follower, and configure downstream Dependencies to send Writes to this new Leader + configure all other Follower to get the changes from the new Leader.
									Problems:
										Unreplicated / Partially Replicated Writes of old Leader to Followers.
										Accidental Failovers from temporary Network Congestion.
										Split Brain: Old Leader associates itself to still be a Leader upon recovery and accepts Writes, leading to an inconsistent Data State across the Cluster.

						Multi-Leader: 
							Characteristics:


							Scenarios:


						Leaderless: 
							Characteristics:
								

							Scenarios:
								



		Database Types:
			In-Memory Database: 	A Database which stores Data in Main Memory, which is much faster than Disk Storage as I/O is skipped. Suitable for Operations in which Response Time is critical.
				Pros:


				Cons:


				Examples:

			Relational Database: Consists of Tables storing Rows of Structured Data.
				Pros:
					ACID-strengthened Transactions:
						Atomicity:		Transactions containing multiple Statements will either succeed as a whole, or not be processed at all.
						Consistency:	Transactions can only bring the Database from one valid State to another, respecting Constraints, Cascades and Triggers within affected Data.
						Isolation: 		Transactions executed concurrently will behave the same if the Transactions are executed sequentially.
						Durability:		Transactions that have been commited will remain commited, even during System Failure (Power Outage / Crash).

						Benefits diminish in Distributed Settings.

					Relational Structure allows minimization of Data Duplication across Tables.

				Cons:
					Scalability:
						CAP Theorem suggests that Availability, Consistency and Partition Tolerance cannot be satisfied at the same time.
						Row-Based Data Structure not optimal for Data Compression.

						Challenging to Horizontally Partition due to JOINs.
						Data may not always be stored in one Partition / Machine, and may require several Network Calls to fulfill.

				Related Content:
					SQL
					NewSQL:		Seeks to combine the strengths of Relational Databases with the strengths of Document Databases.

				Examples:
					PrestoDB:	Facebook's Distributed SQL Query Engine.

			NoSQL: Anything that is not storing Data in a Structured Table Format:
				Document Database:
					Pros:
						Performance:
							Data Locality minimizes the distance of Disk Lookups, as the Document is usually stored in one place on Disk, and in one Machine.

						Scalability:
							Easier to Horizontally Partition without ACID Considerations.

					Cons:
						Larger Network Calls as a result of sending over whole Documents with unneeded Information.

					Related Content:

					Examples:
						MongoDB
						DynamoDB:	Amazon's NoSQL Solution.
						Firestorm

				Graph Database: Stores Data in a Graph (i.e. Vertices and Edges). Queries involve traversing the Graph.
					Pros:
						Good for storing Heterogenous and Homogenous Types of Data.

					Cons:

					Related Content:

					Examples:
						Cassandra

				Key-Value Database:
					Pros:

					Cons:

					Related Content:

					Examples:
						Redis: In-Memory based Database with Disk Persistence that is often used as a Caching Layer on top of other RDBMSes.

			Data Warehouse


	Commands:
		
	
