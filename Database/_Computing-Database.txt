Database
	Abbreviations: 
		DBMS:					DataBase Management System.

		CMDB: 					Configuration Management Database.

	Description: 
		A Database is an Organized, Long-Term Collection of Data, generally Stored, Managed and Accessed via some System.
	
	Resources:
	
	Concepts:
		Data Types:
			Structured Data:	Data whose Elements are Directly Addressible (i.e. Tabular or Array-like Data).
			Semi-Structured Data: Data whose Elements may not be Directly Addressible, but still contain other forms of Organizational Properties (i.e. Tagged Data: XML).
			Unstructured Data:	Data which is currently observed to have no immediately helpful Pre-Defined Format (i.e. Binary Data: PDFs).

		Attribute / Key / Field: Refers to a characteristic of some type of Entity.
		Record:					A collection of Attributes pertaining to some instance of an Entity.
		Collection:				A table of Records.

		Index: 					An additional Data Structure (separate from the Collection) that allows for quick access of a Full Record on Disk via a defined subset of the Record's Data.
			Sparse Index:		Contains a mapping only for every n Records in the Collection to the Disk Location. Typically used in Multi-Level Indexing (i.e further Indexing of a Dense or overly Large Index).
			Dense Index:		Contains a mapping for every Record in the Collection to the Disk Location.

		Database Partitioning:
			Horizontal Partitioning: Different Records into Separate Collections (e.g. Sharding).
			Vertical Partitioning: Different Record Attributes into Separate Collections (e.g. Normalization or simple Record Splitting).

	Details:
		Database Objectives:
			Persistent Data Storage: Data should not be lost when the Database shuts down.

			Fast Writes
			Fast Reads
				Data should be stored contiguously on Disk to minimize the amount of Disk Lookups required (known to be expensive as it involves mechanical movement of the Storage Disks at the Hardware level).

				Optimization Techniques:
					Append-Only: New Records / Updated-versions of Past Records are simply appended to the end of the Collection without concern for Duplication. Lookups can be optimized by traversing from the end of the Collection.

					Indexes: 	Improves speed of Lookups, but imposes additional operations during Insertions / Deletions, and adds to the Storage Space required by the Collection.
						For very large Collections, a Multi-Level Index may be used to avoid sequential Storage Block lookups in the original Index.

						The Data within the Index is usually stored in sorted order, but the actual Records in the Collection on Disk may not be stored in sorted order.

						The optimization is more effective when Records are large => Less Records per Disk Partition => More Disk Lookups without an Index.

						Types:
							Hashmaps: Index Keys map to Memory Addresses (Byte Offsets) in Disk.
								Pros:
									Compatable with the Append-Only method of adding new Records to the Collection.
									Allows access to Records in Constant Time.

								Cons: 
									Entire Hashmap has to be In-Memory for it to be effective - useful for only small Datasets.
									Not good for Range Queries, as Data within the Index is unsorted.

							LSM Trees + Immutable SS Tables: 
								Approach:
									Full Records realized from Database Writes are first placed in an In-Memory Balanced Binary Search Tree, with the Key used in the BST being the Index Key(s).
										To increase persistence, keep a Log on Database Writes that can be used to restore the In-Memory BBST after a Database Outage.

									When Tree gets too large, a Sorted SS Table is generated via BST In-Order Traversal and is transferred to Disk.
										The Tree gets emptied each time a SS Table is generated.

									There can be duplicate Keys between multiple Tables (and the Tree itself) - simply prioritise looking for the Key in the Tree, followed by the youngest SS Table to the oldest.
										Sparse Hashmaps with Memory Addresses + Binary Search on Table Keys can be additionally used to optimize lookups within an SS Table.
										Bloom Filters can be additionally used to optimize lookups between SS Tables.

										Tables can be combined in the same approach that Merge Sort uses to combine 2 Sorted Lists - Linear Time Background Operation.
											Prioritise the Key-Value Pair that is in the younger SS Table over the older SS Table.

								Pros:
									Higher Write Throughput due to Records being placed In-Memory at first.
									Uses the Append-Only method of adding new Records to the Collection.
									Allows access to Records in Sub-Linear Time.
									Good for Range Queries (that only use the Keys in the Index), as the Data in the Index is internally Sorted.

								Cons:
									Relatively Slow Reads for Keys that do not exist in the Collection.
									Merging Process for SS Tables can take up Background Resources.

							B Trees: Data is modelled such that it is a Tree, but on Disk.
								Pros:
									Higher Read Throughput - Sub-Linear Time Operation.
									Good for Range Queries (that only use the Keys in the Index), as the Data in the Index is internally Sorted.

								Cons:
									Relatively Slow Writes, as it is being written to Disk vs. In-Memory.
	
		Database Types:
			In-Memory Database: 	A Database which stores Data in Main Memory, which is much faster than Disk Storage as I/O is skipped. Suitable for Operations in which Response Time is critical.
				Pros:


				Cons:


				Examples:


			Relational Database: Consists of Tables storing Rows of Structured Data.
				Pros:
					ACID-strengthened Transactions:
						Atomicity:		Transactions containing multiple Statements will either succeed as a whole, or not be processed at all.
						Consistency:	Transactions can only bring the Database from one valid State to another, respecting Constraints, Cascades and Triggers within affected Data.
						Isolation: 		Transactions executed concurrently will behave the same if the Transactions are executed sequentially.
						Durability:		Transactions that have been commited will remain commited, even during System Failure (Power Outage / Crash).

						Benefits diminish in Distributed Settings.

					Relational Structure allows minimization of Data Duplication across Tables.

				Cons:
					Scalability:
						CAP Theorem suggests that Availability, Consistency and Partition Tolerance cannot be satisfied at the same time.
						Row-Based Data Structure not optimal for Data Compression.

						Challenging to Horizontally Partition due to JOINs.
						Data may not always be stored in one Partition / Machine, and may require several Network Calls to fulfill.

				Related Content:
					SQL
					NewSQL:		Seeks to combine the strengths of Relational Databases with the strengths of Document Databases.

				Examples:
					PrestoDB:	Facebook's Distributed SQL Query Engine.

			NoSQL: Anything that is not storing Data in a Structured Table Format:
				Document Database:
					Pros:
						Performance:
							Data Locality minimizes the distance of Disk Lookups, as the Document is usually stored in one place on Disk, and in one Machine.

						Scalability:
							Easier to Horizontally Partition without ACID Considerations.

					Cons:
						Larger Network Calls as a result of sending over whole Documents with unneeded Information.

					Related Content:

					Examples:
						MongoDB
						DynamoDB:	Amazon's NoSQL Solution.
						Firestorm

				Graph Database: Stores Data in a Graph (i.e. Vertices and Edges). Queries involve traversing the Graph.
					Pros:
						Good for storing Heterogenous and Homogenous Types of Data.

					Cons:

					Related Content:

					Examples:
						Cassandra

				Key-Value Database:
					Pros:

					Cons:

					Related Content:

					Examples:
						Redis: In-Memory based Database with Disk Persistence that is often used as a Caching Layer on top of other RDBMSes.

			Data Warehouse


	Commands:
		
	
